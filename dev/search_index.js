var documenterSearchIndex = {"docs":
[{"location":"randomization/#Randomization-methods","page":"Randomization methods","title":"Randomization methods","text":"","category":"section"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"Most of the methods presented in sampler.jl Samplers are deterministic i.e. sample(n, d, Sampler()::DeterministicSamplingAlgorithm) always produces the same sequence X = (X_1 dots X_n).","category":"page"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"The main issue with deterministic Quasi Monte Carlo sampling is that it does not allow easy error estimation as opposed to plain Monte Carlo where the variance can be estimated.","category":"page"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"A Randomized Quasi Monte Carlo method must respect the two following criteria","category":"page"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"Have X_isim mathbbU(01^d) for each iin 1cdots n.\nPreserve the QMC (low discrepancy) properties of X.","category":"page"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"This randomized version can be used to obtain confidence interval or sensitivity analysis for example.","category":"page"},{"location":"randomization/#API","page":"Randomization methods","title":"API","text":"","category":"section"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"To randomize one can directly use a sampling algorithm with a randomization method as sample(n, d, DeterministicSamplingAlgorim(R = RandomizationMethod())) or sample(n, lb, up, DeterministicSamplingAlgorim(R = RandomizationMethod())).","category":"page"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"Randomization methods can also be used independently, that is, given a matrix X (dtimes n) of n points in dimension d in 01^d one can directly randomize it using randomize(x, ::RandomizationMethod())","category":"page"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"randomize","category":"page"},{"location":"randomization/#QuasiMonteCarlo.randomize","page":"Randomization methods","title":"QuasiMonteCarlo.randomize","text":"randomize(x, R::Shift)\n\nCranley Patterson Rotation i.e. y = (points .+ U) mod 1 where U ‚àº ùïå([0,1]·µà) and points is a d√ón matrix\n\n\n\n\n\nrandomize(x, R::ScrambleMethod)\n\nReturn a scrambled version of x.  The scramble methods implemented are \n\nDigitalShift.\nOwenScramble: Nested Uniform Scramble which was introduced in Owen (1995).\nMatousekScramble: Linear Matrix Scramble which was introduced in Matousek (1998).\n\n\n\n\n\n","category":"function"},{"location":"randomization/#Scrambling-methods","page":"Randomization methods","title":"Scrambling methods","text":"","category":"section"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"ScramblingMethods(base, pad, rng) are well suited for (tmd)-nets. base is the base used to scramble and pad the number of bits in b-ary decomposition i.e. y simeq sum_k=1^textttpad y_ktextttbase^k  pad is generally chosen as gtrsim log_b(n). The implemented ScramblingMethods are","category":"page"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"DigitalShift the simplest and faster method. For a point xin 01^d it does y_k = (x_k + U_k) mod b where U_k  mathbbU(0 cdots b-1)","category":"page"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"  DigitalShift\n  ```\n  - `MatousekScramble` a.k.a Linear Matrix Scramble is what people use in practice. Indeed, the observed performances are similar to `OwenScramble` for a lesser numerical cost.\n    ```@docs\n    MatousekScramble\n    ```\n  - `OwenScramble` a.k.a Nested Uniform Scramble is the most understood theoretically but is more costly to operate.\n    ```@docs\n    OwenScramble\n    ```\n    s\n## Other methods\n\n`Shift(rng)` a.k.a. Cranley Patterson Rotation. It is by far the fastest method, it is used in `LatticeRuleScramble` for example.","category":"page"},{"location":"randomization/#QuasiMonteCarlo.DigitalShift","page":"Randomization methods","title":"QuasiMonteCarlo.DigitalShift","text":"DigitalShift\n\nDigital shift.  randomize(x, R::DigitalShift) returns a scrambled version of x. \n\nThe scramble method is Digital Shift. It scramble each corrdinate in base b as y‚Çñ = (x‚Çñ + U‚Çñ) mod b where U‚Çñ ‚àº ùïå({0:b-1}).  U is the same for every point points but i.i.d along every dimensions.\n\n\n\n\n\n","category":"type"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"@docs   Shift","category":"page"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"\n## Design Matrices\n\nFor numerous independent randomization, use `generate_design_matrices(n, d, ::DeterministicSamplingAlgorithm), ::RandomizationMethod, num_mats)` where `num_mats` is the number of independent `X` generated.","category":"page"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"@docs   generatedesignmatrices","category":"page"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"\n## Example\n\nRandomization of a Faure sequence with various methods.\n","category":"page"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"julia using QuasiMonteCarlo m = 4 d = 3 b = QuasiMonteCarlo.nextprime(d) N = b^m # Number of points pad = m # Can also choose something as 2m to get \"better\" randomization","category":"page"},{"location":"randomization/#Unrandomized-low-discrepency-sequence","page":"Randomization methods","title":"Unrandomized low discrepency sequence","text":"","category":"section"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"x_faure = QuasiMonteCarlo.sample(N, d, FaureSample())","category":"page"},{"location":"randomization/#Randomized-version","page":"Randomization methods","title":"Randomized version","text":"","category":"section"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"xnus = randomize(xfaure, OwenScramble(base = b, pad = pad)) # equivalent to sample(N, d, FaureSample(R = OwenScramble(base = b, pad = pad))) xlms = randomize(xfaure, MatousekScramble(base = b, pad = pad)) xdigitalshift = randomize(xfaure, DigitalShift(base = b, pad = pad)) xshift = randomize(xfaure, Shift()) xuniform = rand(d, N) # plain i.i.d. uniform","category":"page"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"","category":"page"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"julia using Plots","category":"page"},{"location":"randomization/#Setting-I-like-for-plotting","page":"Randomization methods","title":"Setting I like for plotting","text":"","category":"section"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"default(fontfamily=\"Computer Modern\", linewidth=1, label=nothing, grid=true, framestyle=:default)","category":"page"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"\nPlot the resulting sequences along dimensions `1` and `3`.\n","category":"page"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"julia d1 = 1 d2 = 3 # you can try every combination of dimension (d1, d2) sequences = [xuniform, xfaure, xshift, xdigitalshift, xlms, xnus] names = [\"Uniform\", \"Faure (deterministic)\", \"Shift\", \"Digital Shift\", \"Matousek Scramble\", \"Owen Scramble\"] p = [plot(thicknessscaling=1.5, aspect_ratio=:equal) for i in sequences] for (i, x) in enumerate(sequences)     scatter!(p[i], x[d1, :], x[d2, :], ms=0.9, c=1, grid=false)     title!(names[i])     xlims!(p[i], (0, 1))     ylims!(p[i], (0, 1))     yticks!(p[i], [0, 1])     xticks!(p[i], [0, 1])     hline!(p[i], range(0, 1, step=1 / 4), c=:gray, alpha=0.2)     vline!(p[i], range(0, 1, step=1 / 4), c=:gray, alpha=0.2)     hline!(p[i], range(0, 1, step=1 / 2), c=:gray, alpha=0.8)     vline!(p[i], range(0, 1, step=1 / 2), c=:gray, alpha=0.8) end plot(p..., size=(1500, 900))","category":"page"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"\n![Different randomize methods of the same initial set of points](../../img/various_randomization.svg)\n\nFaure nets and scrambled versions of Faure nets are digital $(t,m,d)$-net ([see this nice book by A. Owen](https://artowen.su.domains/mc/qmcstuff.pdf)). It basically means that they have strong equipartition properties.\nHere we can (visually) verify that with Nested Uniform Scrambling (it also works with Linear Matrix Scrambling and Digital Shift).\nYou must see one point per rectangle of volume $1/b^m$. Points on the \"left\" border of rectangles are included while those on the \"right\" are excluded.\n","category":"page"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"julia begin     d1 = 1      d2 = 3 # you can try every combination of dimension (d1, d2)     x = xnus # Owen Scramble, you can try xlms and xdigitalshift     p = [plot(thicknessscaling=1.5, aspectratio=:equal) for i in 0:m]     for i in 0:m         j = m - i         x·µ¢ = range(0, 1, step=1 / b^(i))         x‚±º = range(0, 1, step=1 / b^(j))         scatter!(p[i+1], x[d1, :], x[d2, :], ms=2, c=1, grid=false)         xlims!(p[i+1], (0, 1.01))         ylims!(p[i+1], (0, 1.01))         yticks!(p[i+1], [0, 1])         xticks!(p[i+1], [0, 1])         hline!(p[i+1], x·µ¢, c=:gray, alpha=0.2)         vline!(p[i+1], x‚±º, c=:gray, alpha=0.2)     end     plot(p..., size=(1500, 900)) end ```","category":"page"},{"location":"randomization/","page":"Randomization methods","title":"Randomization methods","text":"(Image: All the different elementary rectangle contain only one points)","category":"page"},{"location":"#QuasiMonteCarlo.jl:-Quasi-Monte-Carlo-(QMC)-Samples-Made-Easy","page":"Home","title":"QuasiMonteCarlo.jl: Quasi-Monte Carlo (QMC) Samples Made Easy","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"QuasiMonteCarlo.jl is a lightweight package for generating Quasi-Monte Carlo (QMC) samples using various different methods.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To install QuasiMonteCarlo.jl, use the Julia package manager:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"QuasiMonteCarlo\")","category":"page"},{"location":"#Example","page":"Home","title":"Example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"using QuasiMonteCarlo, Distributions\nlb = [0.1,-0.5]\nub = [1.0,20.0]\nn = 5\nd = 2\n\ns = QuasiMonteCarlo.sample(n,lb,ub,GridSample([0.1,0.5]))\ns = QuasiMonteCarlo.sample(n,lb,ub,UniformSample())\ns = QuasiMonteCarlo.sample(n,lb,ub,SobolSample())\ns = QuasiMonteCarlo.sample(n,lb,ub,LatinHypercubeSample())\ns = QuasiMonteCarlo.sample(n,lb,ub,LatticeRuleSample())\ns = QuasiMonteCarlo.sample(n,lb,ub,HaltonSample([10,3]))","category":"page"},{"location":"","page":"Home","title":"Home","text":"The output s is a matrix, so one can use things like @uview from UnsafeArrays.jl for a stack-allocated view of the ith point:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using UnsafeArrays\n@uview s[:,i]","category":"page"},{"location":"#Adding-a-new-sampling-method","page":"Home","title":"Adding a new sampling method","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Adding a new sampling method is a two-step process:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Add a new SamplingAlgorithm type.\nOverload the sample function with the new type.","category":"page"},{"location":"","page":"Home","title":"Home","text":"All sampling methods are expected to return a matrix with dimension d by n, where d is the dimension of the sample space and n is the number of samples.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Example","category":"page"},{"location":"","page":"Home","title":"Home","text":"struct NewAmazingSamplingAlgorithm{OPTIONAL} <: SamplingAlgorithm end\n\nfunction sample(n,lb,ub,::NewAmazingSamplingAlgorithm)\n    if lb isa Number\n        ...\n        return x\n    else\n        ...\n        return reduce(hcat, x)\n    end\nend","category":"page"},{"location":"#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to SciML.\nThere are a few community forums:\nthe #diffeq-bridged channel in the Julia Slack\nJuliaDiffEq on Gitter\non the Julia Discourse forums\nsee also SciML Community page","category":"page"},{"location":"#Reproducibility","page":"Home","title":"Reproducibility","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"<details><summary>The documentation of this SciML package was built using these direct dependencies,</summary>","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg # hide\nPkg.status() # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"</details>","category":"page"},{"location":"","page":"Home","title":"Home","text":"<details><summary>and using this machine and Julia version.</summary>","category":"page"},{"location":"","page":"Home","title":"Home","text":"using InteractiveUtils # hide\nversioninfo() # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"</details>","category":"page"},{"location":"","page":"Home","title":"Home","text":"<details><summary>A more complete overview of all dependencies and their versions is also provided.</summary>","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg # hide\nPkg.status(;mode = PKGMODE_MANIFEST) # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"</details>","category":"page"},{"location":"","page":"Home","title":"Home","text":"You can also download the\n<a href=\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"using TOML\nversion = TOML.parse(read(\"../../Project.toml\",String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\",String))[\"name\"]\nlink = \"https://github.com/SciML/\"*name*\".jl/tree/gh-pages/v\"*version*\"/assets/Manifest.toml\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"\">manifest</a> file and the\n<a href=\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"using TOML\nversion = TOML.parse(read(\"../../Project.toml\",String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\",String))[\"name\"]\nlink = \"https://github.com/SciML/\"*name*\".jl/tree/gh-pages/v\"*version*\"/assets/Project.toml\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"\">project</a> file.","category":"page"},{"location":"samplers/#Sampler-APIs","page":"Sampler APIs","title":"Sampler APIs","text":"","category":"section"},{"location":"samplers/#Sample","page":"Sampler APIs","title":"Sample","text":"","category":"section"},{"location":"samplers/","page":"Sampler APIs","title":"Sampler APIs","text":"sample","category":"page"},{"location":"samplers/#Samplers","page":"Sampler APIs","title":"Samplers","text":"","category":"section"},{"location":"samplers/","page":"Sampler APIs","title":"Sampler APIs","text":"Samplers are divided into two subtypes","category":"page"},{"location":"samplers/","page":"Sampler APIs","title":"Sampler APIs","text":"abstract type SamplingAlgorithm end\nabstract type RandomSamplingAlgorithm <: SamplingAlgorithm end\nabstract type DeterministicSamplingAlgorithm <: SamplingAlgorithm end","category":"page"},{"location":"samplers/#Deterministic-Sampling-Algorithm","page":"Sampler APIs","title":"Deterministic Sampling Algorithm","text":"","category":"section"},{"location":"samplers/","page":"Sampler APIs","title":"Sampler APIs","text":"GridSample\nSobolSample\nLatticeRuleSample\nHaltonSample\nGoldenSample\nKroneckerSample","category":"page"},{"location":"samplers/#QuasiMonteCarlo.GridSample","page":"Sampler APIs","title":"QuasiMonteCarlo.GridSample","text":"GridSample()\n\nA simple rectangular grid lattice.\n\nIn more than 2 dimensions, grids have worse discrepancy than simple Monte Carlo. As a result, they should almost never be used for multivariate integration; their use is as a starting point for other algorithms.\n\n\n\n\n\n","category":"type"},{"location":"samplers/#QuasiMonteCarlo.SobolSample","page":"Sampler APIs","title":"QuasiMonteCarlo.SobolSample","text":"SobolSample <: DeterministicSamplingAlgorithm\n\nSamples taken from Sobol's base-2 sequence.\n\n\n\n\n\n","category":"type"},{"location":"samplers/#QuasiMonteCarlo.LatticeRuleSample","page":"Sampler APIs","title":"QuasiMonteCarlo.LatticeRuleSample","text":"LatticeRuleSample()\n\nGenerate a point set using a lattice rule.\n\n\n\n\n\n","category":"type"},{"location":"samplers/#QuasiMonteCarlo.HaltonSample","page":"Sampler APIs","title":"QuasiMonteCarlo.HaltonSample","text":"HaltonSample()\n\nCreate a Halton sequence.\n\n\n\n\n\n","category":"type"},{"location":"samplers/#QuasiMonteCarlo.GoldenSample","page":"Sampler APIs","title":"QuasiMonteCarlo.GoldenSample","text":"GoldenSample()\n\nGenerate a quasirandom Kronecker sequence using powers of the generalized golden ratio.\n\nThe harmonious, or generalized golden, ratios are defined as the solutions to the equation: x^d = x + 1\n\nWhere d is the dimension of the sequence. The Golden sequence is then equivalent to Kronecker([x^-i for i in 1:d]).\n\nWARNING: the generalized golden sequence in more than 2 dimensions is purely experimental. It likely has poor discrepancy in high dimensions, and should not be used without verifying answers against a better-known quasirandom sequence. Try a rank-1 lattice rule instead.\n\nReferences: Roberts, M. (2018). The Unreasonable Effectiveness of Quasirandom Sequences. Extreme Learning. http://extremelearning.com.au/unreasonable-effectiveness-of-quasirandom-sequences/\n\n\n\n\n\n","category":"function"},{"location":"samplers/#QuasiMonteCarlo.KroneckerSample","page":"Sampler APIs","title":"QuasiMonteCarlo.KroneckerSample","text":"KroneckerSample(generator::AbstractVector) <: DeterministicSamplingAlgorithm\n\nA Kronecker sequence is a point set generated using a vector and equation: x[i] = i * generator .% 1\n\nWhere i runs from 1 through the sample size n. This sequence will be equidistributed (uniform in the infinite limit) so long as the components of generator are linearly independent over the field of rational numbers.\n\nIf no generator is specified, a lattice based on the generalized golden ratio is used; see GoldenSample for more information.\n\nKronecker sequences are not recommended for use in more than 3 dimensions, as theory on them is sparse. LatticeRuleSample will return rank-1 lattice rules, which behave similarly to Kronecker sequences but have better properties.\n\nReferences: Leobacher, G., & Pillichshammer, F. (2014). Introduction to quasi-Monte Carlo integration and applications. Switzerland: Springer International Publishing. https://link.springer.com/content/pdf/10.1007/978-3-319-03425-6.pdf\n\n\n\n\n\n","category":"type"},{"location":"samplers/#Random-Sampling-Algorithm","page":"Sampler APIs","title":"Random Sampling Algorithm","text":"","category":"section"},{"location":"samplers/","page":"Sampler APIs","title":"Sampler APIs","text":"UniformSample\nLatinHypercubeSample\n<!-- SectionSample -->","category":"page"},{"location":"samplers/#QuasiMonteCarlo.LatinHypercubeSample","page":"Sampler APIs","title":"QuasiMonteCarlo.LatinHypercubeSample","text":"LatinHypercubeSample <: RandomSamplingAlgorithm\n\nA Latin Hypercube is a point set with the property that every one-dimensional interval (i/n, i+1/n) contains exactly one point. This is a good way to sample a high-dimensional space, as it is more uniform than a random sample but does not require as many points as a full net.\n\n\n\n\n\n","category":"type"}]
}
